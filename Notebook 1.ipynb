{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "from gym import envs\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env in envs.registry.all():\n",
    "    print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(210, 160, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('PongNoFrameskip-v0')\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " [[109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " [[109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]]\n",
      "[[[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " [[109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " [[109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]] 0.0 False {'ale.lives': 0}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('PongNoFrameskip-v0')\n",
    "observation = env.reset()\n",
    "\n",
    "\n",
    "env.render()\n",
    "print(observation)\n",
    "action = env.action_space.sample()\n",
    "a, b, c, d = env.step(action)\n",
    "print(a,b,c,d)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to see visual\n",
    "\n",
    "for i_episode in range(2):\n",
    "    observation = env.reset()\n",
    "    for t in range(1000):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, log = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('PongNoFrameskip-v0')\n",
    "observation = env.reset()\n",
    "\n",
    "\n",
    "# env.render()\n",
    "print(observation)\n",
    "# action = env.action_space.sample()\n",
    "# a, b, c, d = env.step(action)\n",
    "# print(a,b,c,d)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c82214482147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pobservation = torch.from_numpy(observation)\n",
    "pobservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_pobservation = pobservation.view(1,-1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenobs = len(flattened_pobservation[0])\n",
    "lenobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_pobservation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ANNmodel(flattened_pobservation)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling from actions\n",
    "action = np.random.choice(np.array([0,1]), p = preds.view(2,).data.numpy())\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate model\n",
    "ANNmodel2 = nn.Sequential(\n",
    "           nn.Linear(lenobs, 2000),\n",
    "           nn.LeakyReLU(),\n",
    "           nn.Linear(2000,2),\n",
    "           nn.LeakyReLU(),\n",
    "           nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenobs = 100800\n",
    "ANNmodel1 = nn.Sequential(\n",
    "           nn.Linear(lenobs, 2000),\n",
    "           nn.Sigmoid(),\n",
    "           nn.Linear(2000,2),\n",
    "           nn.Sigmoid(),\n",
    "           nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenobs = 100800\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.l1 = nn.Linear(lenobs,25)\n",
    "        self.l2 = nn.Linear(25,50)\n",
    "        self.actor_lin1 = nn.Linear(50,2)\n",
    "        self.l3 = nn.Linear(50,25)\n",
    "        self.critic_lin1 = nn.Linear(25,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x,dim=0)\n",
    "        y = F.relu(self.l1(x))\n",
    "        y = F.relu(self.l2(y))\n",
    "        actor = F.softmax(self.actor_lin1(y),dim=0)\n",
    "#         actor = F.log_softmax(self.actor_lin1(y),dim=0)\n",
    "        c = F.relu(self.l3(y.detach()))\n",
    "        critic = torch.tanh(self.critic_lin1(c))\n",
    "        return actor, critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Episode:0 State:3056 Reward:-1.0\n",
      "Episode finished after 3057 timesteps\n",
      "Loss: -113.89744567871094\n",
      "---------------\n",
      "Episode:1 State:3056 Reward:-1.0\n",
      "Episode finished after 3057 timesteps\n",
      "Loss: -113.91683197021484\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('PongNoFrameskip-v0')\n",
    "moveMapping = {\n",
    "    0:2,\n",
    "    1:3\n",
    "}\n",
    "\n",
    "model = ActorCritic()\n",
    "optimizer = optim.Adam(lr=1e-4,params=model.parameters())\n",
    "\n",
    "'''\n",
    "loss = Variable(loss, requires_grad = True)\n",
    "actor_loss = Variable(actor_loss, requires_grad = True)\n",
    "critic_loss = Variable(critic_loss, requires_grad = True)\n",
    "'''\n",
    "\n",
    "for i_episode in range(2):\n",
    "#     reward = 0.0\n",
    "    values = []\n",
    "    rewards = []\n",
    "    logprobs = []\n",
    "    observation = env.reset()\n",
    "    print('---------------')\n",
    "    done = False\n",
    "    t = 0\n",
    "    while done == False:\n",
    "        t+=1\n",
    "#         print(t)\n",
    "        pobservation = torch.from_numpy(observation)\n",
    "        flattened_pobservation = pobservation.view(-1).float()\n",
    "        policy, value = model(flattened_pobservation)\n",
    "#         print(policy)\n",
    "        values.append(value)\n",
    "        action = np.random.choice(np.array([0,1]), p = policy.view(2,).data.numpy())\n",
    "        logprobs.append(policy.view(-1)[action])\n",
    "#         print('Action: {}'.format('right' if action==2 else 'left'))\n",
    "        observation, reward, done, log = env.step(moveMapping[action])\n",
    "        rewards.append(reward)\n",
    "#         print('{}.Reward: {}'.format(t,reward))\n",
    "#         print('---')\n",
    "        if done:\n",
    "            print('Episode:{} State:{} Reward:{}'.format(i_episode,t,reward))\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))    \n",
    "            break\n",
    "        \n",
    "      \n",
    "    # Reversing because earlier actions have greater value\n",
    "    torch_values = torch.tensor(values, requires_grad = True).view(-1).flip(0)\n",
    "    torch_rewards = torch.tensor(rewards, requires_grad = True).flip(0)\n",
    "    torch_logprobs = torch.tensor(logprobs, requires_grad = True).flip(0)\n",
    "    \n",
    "    \n",
    "    returns = []\n",
    "    gamma = 0.95\n",
    "    clc = 0.1\n",
    "    ret = torch.tensor([0])\n",
    "    for r in torch_rewards:\n",
    "        ret = r + gamma*ret\n",
    "        returns.append(ret)\n",
    "    returns = torch.tensor(returns, requires_grad = True)\n",
    "    returns = F.normalize(returns,dim=0)\n",
    "    actor_loss = -1*torch_logprobs * (returns - torch_values)\n",
    "    critic_loss = torch.pow(torch_values - returns,2)\n",
    "    loss = actor_loss.sum() + clc*critic_loss.sum()\n",
    "    print('Loss: {}'.format(loss))\n",
    "#     print('Starting Backpropagation')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     print('Completed Backpropagation')\n",
    "    done = not done\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Checking operations of pong #######################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Experimenting with Backpropagation ######################\n",
    "\n",
    "inp = torch.tensor([2.,3.]).float()\n",
    "weights = torch.tensor([1.,9.], requires_grad = True).float()\n",
    "print(\"Params: \",weights)\n",
    "gt = torch.tensor([6.])\n",
    "print(\"Ground truth: \",gt)\n",
    "out = torch.dot(inp,weights)\n",
    "print(\"Prediction: \",out)\n",
    "\n",
    "error = (gt - out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([weights],lr = 0.1)\n",
    "optimizer.zero_grad()\n",
    "error.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# print(ANNmodel.weight.grad)\n",
    "weights.grad, out.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights after one round of backpropagation\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking variables with requires_grad\n",
    "inp.requires_grad, weights.requires_grad, gt.requires_grad, out.requires_grad, error.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Manually setting gradients #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinorModel2 = nn.Sequential( \n",
    "             nn.Linear(2,1, bias = False))\n",
    "\n",
    "inp = torch.tensor([2.,3.])\n",
    "out = MinorModel(inp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in MinorModel2.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinorModel2[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinorModel2[0].weight.grad = torch.Tensor([1,2]).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2 = optim.SGD(MinorModel2.parameters(), lr=0.1)\n",
    "\n",
    "o2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in MinorModel2.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Testing ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MinorModel = nn.Sequential( \n",
    "             nn.Linear(2,1, bias = False))\n",
    "\n",
    "inp = torch.tensor([2.,3.])\n",
    "out = MinorModel(inp)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, params in MinorModel.named_parameters():\n",
    "    print(name, params)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for params in MinorModel.parameters():\n",
    "    print(params)\n",
    "    print(type(params))\n",
    "    \n",
    "print(MinorModel.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Experimentations ###############################################\n",
    "\n",
    "# from torch.distributions import Categorical\n",
    "# a = torch.tensor([20,20,20,20,20]).float()\n",
    "# # Note that this is equivalent to what used to be called multinomial\n",
    "# m = Categorical(a)\n",
    "\n",
    "# li = [0,0,0,0,0]\n",
    "\n",
    "\n",
    "# for i in range(100):\n",
    "#     li[m.sample().item()] +=1\n",
    "    \n",
    "# li\n",
    "\n",
    "# a = torch.tensor(3)\n",
    "# a.item()\n",
    "\n",
    "\n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation for cropping and grayscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision import transforms\n",
    "\n",
    "observation = env.reset()\n",
    "for _ in range(685):\n",
    "    observation, reward, done, log = env.step(1)\n",
    "\n",
    "\n",
    "tobservation = torch.from_numpy(observation).permute(2,0,1)\n",
    "# observation.shape # 210, 160, 3\n",
    "# tobservation.shape # 210 160 3\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "])\n",
    "\n",
    "cropped_image = transforms.functional.crop(preprocess(tobservation),32,15,163,130)\n",
    "\n",
    "gs_image = transforms.functional.to_grayscale(cropped_image)\n",
    "\n",
    "gs_tensor = transforms.ToTensor()(gs_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gs_tensor.shape\n",
    "plt.imshow(gs_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "eps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "for i in range(0, 9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    tobservation = torch.from_numpy(observation)\n",
    "    pyplot.imshow(tobservation)\n",
    "    observation, reward, done, log = env.step(1)\n",
    "    eps+=1\n",
    "    \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelized training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizer\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "    \n",
    "class mymodel(nn.Module):\n",
    "    def __init__(self, ran):\n",
    "        super(mymodel,self).__init__()\n",
    "        torch.random.manual_seed(ran)\n",
    "        self.weight = nn.Linear(3,2)\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.out = self.weight(X)\n",
    "        self.out = nn.Softmax(dim = 0)(out)\n",
    "        return self.out\n",
    "\n",
    "\n",
    "        \n",
    "def doTrain(model, ran, X):     \n",
    "    a1 = model(ran)\n",
    "    return list(a1.parameters())\n",
    "\n",
    "X = torch.randn(20,3)\n",
    "\n",
    "\n",
    "updatedParams = []\n",
    "results = []\n",
    "\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    for i in range(5):\n",
    "        results.append(executor.submit(doTrain, mymodel, int((torch.randn(1)**2)*200), X[i*4:(i+1)*4]))\n",
    "    \n",
    "\n",
    "    for f in concurrent.futures.as_completed(results):\n",
    "        updatedParams.append(f.result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedW = torch.zeros(2,3)\n",
    "updatedB = torch.zeros(2)\n",
    "\n",
    "for i in updatedParams:\n",
    "    updatedW+=i[0]\n",
    "for i in updatedParams:\n",
    "    updatedB+=i[1]\n",
    "    \n",
    "updatedW/=5.0\n",
    "updatedB/=5.0\n",
    "\n",
    "updatedW, updatedB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updatedWts = (updatedParams[0][0]+updatedParams[1][0]+updatedParams[2][0]+updatedParams[3][0]+updatedParams[4][0])/5.0\n",
    "# updatedBias = (updatedParams[0][1]+updatedParams[1][1]+updatedParams[2][1]+updatedParams[3][1]+updatedParams[4][1])/5.0\n",
    "# updatedWts, updatedBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
